"""
ë¬¸ì„œ ë¶„ì„ ëª¨ë“ˆ
- ê¸°ìˆ  ë¶„ì•¼ ìžë™ ì‹ë³„
- í•µì‹¬ ìš©ì–´ ìžë™ ì¶”ì¶œ
- ë°˜ë³µ íŒ¨í„´ ê°ì§€
"""

import re
import json
import os
import yaml
from pathlib import Path
from typing import Dict, List, Tuple
from collections import Counter
import google.generativeai as genai
from dotenv import load_dotenv

load_dotenv()


class DocumentAnalyzer:
    """íŠ¹í—ˆ ë¬¸ì„œ ë¶„ì„ê¸°"""

    def __init__(self, 
                 terminology_path: str = "config/terminology.json",
                 api_config_path: str = "config/api_config.yaml"):
        self.terminology_path = Path(terminology_path)
        self.terminology = self._load_terminology()

        # API í‚¤ ë° ëª¨ë¸ ì„¤ì •
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            raise ValueError("GOOGLE_API_KEY í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.")
        genai.configure(api_key=api_key)

        with open(api_config_path, 'r', encoding='utf-8') as f:
            api_config = yaml.safe_load(f)
        
        google_config = api_config.get("google", {})
        model_name = google_config.get("model", "gemini-2.5-flash")
        
        self.model = genai.GenerativeModel(model_name)
        self.generation_config = genai.types.GenerationConfig(
            max_output_tokens=google_config.get("max_output_tokens", 8192),
            temperature=google_config.get("temperature", 0.0)
        )

    def _load_terminology(self) -> Dict:
        """ìš©ì–´ì§‘ ë¡œë“œ"""
        with open(self.terminology_path, 'r', encoding='utf-8') as f:
            return json.load(f)

    def identify_domain(self, text: str) -> str:
        """ê¸°ìˆ  ë¶„ì•¼ ì‹ë³„"""
        domain_keywords = {
            "electronics_semiconductor": ["substrate", "layer", "semiconductor", "wafer", "transistor", "chip", "circuit"],
            "chemistry_pharma": ["compound", "molecule", "pharmaceutical", "drug", "synthesis", "reaction", "chemical"],
            "mechanical": ["distal", "proximal", "apparatus", "device", "mechanical", "housing"],
            "biotech": ["protein", "cell", "antibody", "gene", "DNA", "RNA", "biological"]
        }
        text_lower = text.lower()
        scores = {domain: sum(1 for kw in keywords if kw in text_lower) for domain, keywords in domain_keywords.items()}
        return max(scores, key=scores.get) if max(scores.values()) > 0 else "general"

    def extract_technical_terms(self, text: str, top_n: int = 20) -> List[Tuple[str, int]]:
        """í•µì‹¬ ê¸°ìˆ  ìš©ì–´ ì¶”ì¶œ"""
        patterns = [
            r'\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\b',
            r'\b(?:substrate|layer|compound|method|device|system|apparatus)\b',
        ]
        terms = [match for pattern in patterns for match in re.findall(pattern, text)]
        term_counts = Counter(terms)
        stopwords = {'The', 'A', 'An', 'In', 'Of', 'And', 'Or', 'To', 'For', 'With', 'By', 'At'}
        filtered_terms = [(term, count) for term, count in term_counts.most_common(top_n * 2) if term not in stopwords and len(term) > 2]
        return filtered_terms[:top_n]

    def identify_patterns(self, text: str) -> List[str]:
        """ë°˜ë³µ íŒ¨í„´ ì‹ë³„"""
        patterns = {
            "comprising": r"comprising\s+[A-Za-z,\s]+", "wherein": r"wherein\s+[^.;]+",
            "selected from": r"selected\s+from\s+[^.;]+", "consisting of": r"consisting\s+of\s+[^.;]+"
        }
        found_patterns = [f"{name}: {len(matches)}íšŒ ì¶œí˜„" for name, pattern in patterns.items() if len(matches := re.findall(pattern, text, re.IGNORECASE)) >= 2]
        return found_patterns

    def analyze_with_gemini(self, text: str, domain: str) -> Dict:
        """Gemini APIë¥¼ ì‚¬ìš©í•œ ì‹¬ì¸µ ë¶„ì„"""
        prompt = f"""You are a patent translation expert analyzing an English patent document.

Domain identified: {domain}

Analyze the following text and provide:
1. Top 20 key technical terms that should be translated consistently.
2. The document type (claim, specification, or abstract).
3. Important phrases that repeat 3 or more times.
4. Suggested Korean terminology for domain-specific terms based on the identified domain: {domain}.

Text to analyze:
---
{text[:4000]}
---

Provide your analysis in a structured JSON format. The JSON output should be clean, without any surrounding text or markdown.

Example JSON structure:
{{
  "key_terms": ["term1", "term2", ...],
  "document_type": "claim",
  "repeated_phrases": ["phrase1", "phrase2", ...],
  "domain_specific_terms": {{
    "english_term_1": "korean_translation_1",
    "english_term_2": "korean_translation_2"
  }}
}}
"""
        try:
            response = self.model.generate_content(prompt, generation_config=self.generation_config)
            # Gemini ì‘ë‹µì—ì„œ JSONë§Œ ì •ë¦¬í•˜ì—¬ ì¶”ì¶œ
            clean_json_str = re.search(r'\{.*\}', response.text, re.DOTALL)
            if clean_json_str:
                return json.loads(clean_json_str.group())
            return {}
        except Exception as e:
            print(f"Gemini ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {}

    def analyze(self, text: str, use_ai: bool = True) -> Dict:
        """ì „ì²´ ë¬¸ì„œ ë¶„ì„"""
        print("ðŸ“Š ë¬¸ì„œ ë¶„ì„ ì¤‘...")
        domain = self.identify_domain(text)
        print(f"   âœ“ ë„ë©”ì¸ ì‹ë³„: {domain}")
        technical_terms = self.extract_technical_terms(text)
        print(f"   âœ“ ê¸°ìˆ  ìš©ì–´ ì¶”ì¶œ: {len(technical_terms)}ê°œ")
        patterns = self.identify_patterns(text)
        print(f"   âœ“ ë°˜ë³µ íŒ¨í„´: {len(patterns)}ê°œ")

        ai_analysis = {}
        if use_ai:
            print("   â³ Gemini AI ì‹¬ì¸µ ë¶„ì„ ì¤‘...")
            ai_analysis = self.analyze_with_gemini(text, domain)
            print("   âœ“ Gemini ë¶„ì„ ì™„ë£Œ")

        term_mapping = self._build_term_mapping(technical_terms, domain, ai_analysis)
        
        result = {
            "domain": domain, "technical_terms": technical_terms, "patterns": patterns,
            "ai_analysis": ai_analysis, "term_mapping": term_mapping
        }
        print("âœ… ë¬¸ì„œ ë¶„ì„ ì™„ë£Œ\n")
        return result

    def _build_term_mapping(self, technical_terms: List[Tuple[str, int]],
                           domain: str, ai_analysis: Dict) -> Dict[str, str]:
        """ìš©ì–´ ë§¤í•‘ êµ¬ì¶•"""
        mapping = {}
        domain_terms = self.terminology.get("domain_terms", {}).get(domain, {})
        mapping.update(domain_terms)
        
        general_terms = self.terminology.get("domain_terms", {}).get("general", {})
        for term, _ in technical_terms:
            term_lower = term.lower()
            if term_lower in general_terms:
                mapping[term] = general_terms[term_lower]

        if ai_analysis and "domain_specific_terms" in ai_analysis:
            ai_terms = ai_analysis["domain_specific_terms"]
            for eng, kor in ai_terms.items():
                if eng not in mapping:
                    mapping[eng] = kor
        return mapping

if __name__ == "__main__":
    analyzer = DocumentAnalyzer()
    sample_text = """
    A method for characterizing a protein, comprising:
    obtaining a protein sample; preparing said sample for spectroscopy;
    subjecting said sample to an experiment;
    eliminating noise from empty areas of a resulting spectrum;
    and analyzing the spectrum to characterize the protein.
    """
    result = analyzer.analyze(sample_text, use_ai=False)
    print(json.dumps(result, indent=2, ensure_ascii=False))
