"""
ìë™ QA ê²€ì¦ ì‹œìŠ¤í…œ
- í˜•ì‹ ê·œì¹™ ê²€ì‚¬
- ìš©ì–´ ì¼ê´€ì„± ê²€ì‚¬
- ê¸ˆì§€ ìš©ì–´ ê²€ì‚¬
- ìŠ¤íƒ€ì¼ ê°€ì´ë“œ ì¤€ìˆ˜ í™•ì¸
- QA_CHECKLIST.md ê¸°ë°˜ í¬ê´„ì  ê²€ì‚¬
"""

import re
import json
from typing import Dict, List
from pathlib import Path


class QAViolation:
    """QA ìœ„ë°˜ ì‚¬í•­"""

    def __init__(self, rule_id: str, severity: str, description: str,
                 location: str, found: str, correct: str = ""):
        self.rule_id = rule_id
        self.severity = severity  # critical, major, minor, neutral
        self.description = description
        self.location = location
        self.found = found
        self.correct = correct

    def to_dict(self) -> Dict:
        return {
            "rule_id": self.rule_id,
            "severity": self.severity,
            "description": self.description,
            "location": self.location,
            "found": self.found,
            "correct": self.correct
        }


class PatentQAChecker:
    """íŠ¹í—ˆ ë²ˆì—­ QA ì²´ì»¤"""

    def __init__(self, style_guide_path: str = "config/style_guide.json",
                 terminology_path: str = "config/terminology.json",
                 qa_checklist_path: str = "config/QA_CHECKLIST.md"):
        self.style_guide = self._load_json(style_guide_path)
        self.terminology = self._load_json(terminology_path)
        self.qa_checklist_path = qa_checklist_path
        self.violations: List[QAViolation] = []

        # QA ì²´í¬ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜ ê·œì¹™ ì´ˆê¸°í™”
        self._init_checklist_rules()

    def _load_json(self, path: str) -> Dict:
        """JSON íŒŒì¼ ë¡œë“œ"""
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)

    def _init_checklist_rules(self):
        """QA ì²´í¬ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜ ê·œì¹™ ì´ˆê¸°í™”"""
        # ì²´í¬ë¦¬ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œí•œ ì£¼ìš” ê²€ì‚¬ í•­ëª©ë“¤

        # 1. ê¸ˆì§€ ìš©ì–´ (ë„ë©”ì¸ë³„)
        self.domain_mistranslations = {
            'substrate': {'wrong': 'ê¸°íŒ', 'context': 'í™”í•™', 'correct': 'ê¸°ì¬'},
            'detach': {'wrong': 'íƒˆì°©í•˜ë‹¤', 'correct': 'íƒˆë¦¬í•˜ë‹¤'},
            'fault': {'wrong': 'ì˜¤ë¥˜', 'context': 'ê¸°ê³„/ì „ê¸°', 'correct': 'ê³ ì¥'},
            'source': {'wrong': 'ê³µê¸‰ì›', 'context': 'ë°©ì‚¬ì„ ', 'correct': 'ì„ ì›'},
            'communication': {'wrong': 'í†µì‹ ', 'context': 'ìœ ì²´', 'correct': 'ì—°í†µ'},
            'distal end': {'wrong': 'ë§ë‹¨', 'correct': 'ì›ìœ„ ë‹¨ë¶€'},
            'proximal end': {'wrong': 'ë§ë‹¨', 'correct': 'ê·¼ìœ„ ë‹¨ë¶€'},
            'intake': {'wrong': 'í¡ê¸°êµ¬', 'context': 'ì•¡ì²´', 'correct': 'í¡ì…êµ¬'},
            'ground': {'wrong': 'ì§€ë©´', 'context': 'ì „ê¸°', 'correct': 'ì ‘ì§€'},
            'recite': {'wrong': ['ì•”ì†¡', 'ì—´ê±°'], 'correct': 'ê¸°ìˆ í•˜ë‹¤'},
            'incubate': {'wrong': 'ë°°ì–‘', 'correct': 'ì •ì¹˜'},
            'adapted to': {'wrong': 'ì í•©í™”ëœ', 'correct': '~í•˜ë„ë¡ êµ¬ì„±ëœ'}
        }

        # 2. í‘œì¤€ ìš©ì–´
        self.standard_terms = {
            'embodiment': {'preferred': 'ì‹¤ì‹œí˜•íƒœ', 'forbidden': ['ì‹¤ì‹œíƒœì–‘', 'ì‹¤ì‹œì˜ˆ', 'êµ¬í˜„ì˜ˆ']},
            'aspect': {'preferred': 'ì–‘íƒœ', 'avoid': ['ì–‘ìƒ', 'ì¸¡ë©´']},
            'subject matter': {'correct': ['ëŒ€ìƒë¬¼', 'ëŒ€ìƒ'], 'forbidden': 'ì£¼ì œ'}
        }

        # 3. ìˆ˜ì¹˜ ë¹„êµ ì˜¤ì—­
        self.numerical_comparisons = {
            'more than one': {'wrong': 'í•˜ë‚˜(1ê°œ) ì´ìƒ', 'correct': ['ë‘˜(2ê°œ) ì´ìƒ', 'í•˜ë‚˜(1ê°œ) ì´ˆê³¼']},
            'less than two': {'wrong': 'ë‘˜(2ê°œ) ì´í•˜', 'correct': ['í•˜ë‚˜(1ê°œ) ì´í•˜', 'ë‘˜(2ê°œ) ë¯¸ë§Œ']}
        }

        # 4. ì „í™˜êµ¬
        self.transitional_phrases = {
            'comprising': 'í¬í•¨í•˜ëŠ”',
            'consisting of': ['ì´ë£¨ì–´ì§€ëŠ”', 'êµ¬ì„±ë˜ëŠ”'],
            'consisting essentially of': 'í•„ìˆ˜ì ìœ¼ë¡œ êµ¬ì„±ë˜ëŠ”',
            'characterized by': '~ì„ íŠ¹ì§•ìœ¼ë¡œ í•˜ëŠ”',
            'adapted to': '~í•˜ë„ë¡ êµ¬ì„±ëœ'
        }

    def check_formatting(self, text: str, document_type: str = "claim") -> List[QAViolation]:
        """í˜•ì‹ ê·œì¹™ ê²€ì‚¬"""
        violations = []
        formatting_rules = self.style_guide.get("formatting_rules", {})

        # ì˜¨ë„ í‘œê¸° ê²€ì‚¬
        temp_pattern = r'(\d+)\s*â„ƒ'
        matches = re.finditer(temp_pattern, text)
        for match in matches:
            if not re.match(r'\d+\sâ„ƒ', match.group()):
                violations.append(QAViolation(
                    rule_id="format_temperature",
                    severity="minor",
                    description="ì˜¨ë„ í‘œê¸° ì‹œ ìˆ«ìì™€ ë‹¨ìœ„ ì‚¬ì´ì— ê³µë°± í•„ìš”",
                    location=f"ìœ„ì¹˜: {match.start()}",
                    found=match.group(),
                    correct=f"{match.group(1)} â„ƒ"
                ))

        # í¼ì„¼íŠ¸ í‘œê¸° ê²€ì‚¬
        percent_pattern = r'(\d+)\s*%'
        matches = re.finditer(percent_pattern, text)
        for match in matches:
            if not re.match(r'\d+\s%', match.group()):
                violations.append(QAViolation(
                    rule_id="format_percentage",
                    severity="minor",
                    description="í¼ì„¼íŠ¸ í‘œê¸° ì‹œ ìˆ«ìì™€ ê¸°í˜¸ ì‚¬ì´ì— ê³µë°± í•„ìš”",
                    location=f"ìœ„ì¹˜: {match.start()}",
                    found=match.group(),
                    correct=f"{match.group(1)} %"
                ))

        # ì²­êµ¬í•­ ë§ˆì¹¨í‘œ ê²€ì‚¬
        if document_type == "claim":
            if not text.strip().endswith('.'):
                violations.append(QAViolation(
                    rule_id="claim_ending",
                    severity="major",
                    description="ì²­êµ¬í•­ì€ ë§ˆì¹¨í‘œë¡œ ì¢…ê²°ë˜ì–´ì•¼ í•¨",
                    location="ë¬¸ì¥ ë",
                    found=text.strip()[-20:],
                    correct="... (ë§ˆì¹¨í‘œ ì¶”ê°€)"
                ))

        # ì„œì—´ë²ˆí˜¸ í˜•ì‹ ê²€ì‚¬
        seq_pattern = r'ì„œì—´\s?ë²ˆí˜¸\s?:?\s?(\d+)'
        matches = re.finditer(seq_pattern, text)
        for match in matches:
            if match.group() != f"ì„œì—´ë²ˆí˜¸ {match.group(1)}":
                violations.append(QAViolation(
                    rule_id="seq_id_format",
                    severity="minor",
                    description="ì„œì—´ë²ˆí˜¸ í˜•ì‹: 'ì„œì—´ë²ˆí˜¸ ìˆ«ì'",
                    location=f"ìœ„ì¹˜: {match.start()}",
                    found=match.group(),
                    correct=f"ì„œì—´ë²ˆí˜¸ {match.group(1)}"
                ))

        return violations

    def check_terminology(self, text: str, term_mapping: Dict[str, str]) -> List[QAViolation]:
        """ìš©ì–´ ì¼ê´€ì„± ê²€ì‚¬"""
        violations = []

        # ê¸ˆì§€ ìš©ì–´ ê²€ì‚¬
        forbidden = self.terminology.get("forbidden_translations", {})
        for eng_term, forbidden_list in forbidden.items():
            for forbidden_kr in forbidden_list:
                if forbidden_kr in text:
                    correct_term = term_mapping.get(eng_term, "í™•ì¸ í•„ìš”")
                    violations.append(QAViolation(
                        rule_id=f"forbidden_term_{eng_term}",
                        severity="major",
                        description=f"ê¸ˆì§€ ìš©ì–´ ì‚¬ìš©: {forbidden_kr}",
                        location=f"'{forbidden_kr}' ë°œê²¬",
                        found=forbidden_kr,
                        correct=correct_term
                    ))

        return violations

    def check_antecedent_basis(self, source: str, translation: str) -> List[QAViolation]:
        """ì„ í–‰ì‚¬ 'ìƒê¸°' ê²€ì‚¬"""
        violations = []

        # "the compound/device/method" íŒ¨í„´ ì°¾ê¸°
        the_pattern = r'the\s+(compound|device|method|system|apparatus|composition)'
        matches = re.finditer(the_pattern, source, re.IGNORECASE)

        for match in matches:
            noun = match.group(1)
            # í•œêµ­ì–´ ë²ˆì—­ì—ì„œ í•´ë‹¹ ëª…ì‚¬ ì°¾ê¸°
            noun_kr_map = {
                'compound': 'í™”í•©ë¬¼',
                'device': 'ì¥ì¹˜',
                'method': 'ë°©ë²•',
                'system': 'ì‹œìŠ¤í…œ',
                'apparatus': 'ì¥ì¹˜',
                'composition': 'ì¡°ì„±ë¬¼'
            }

            noun_kr = noun_kr_map.get(noun.lower())
            if noun_kr:
                # "ìƒê¸°"ê°€ ë¶™ì–´ ìˆëŠ”ì§€ í™•ì¸
                sanggi_pattern = f'ìƒê¸°\\s+{noun_kr}'
                if noun_kr in translation and not re.search(sanggi_pattern, translation):
                    violations.append(QAViolation(
                        rule_id="antecedent_basis",
                        severity="major",
                        description="ì„ í–‰ì‚¬ ìˆëŠ” ëª…ì‚¬ì— 'ìƒê¸°' ëˆ„ë½",
                        location=f"'{noun_kr}' ë°œê²¬",
                        found=noun_kr,
                        correct=f"ìƒê¸° {noun_kr}"
                    ))

        return violations

    def check_claim_structure(self, text: str, document_type: str = "claim") -> List[QAViolation]:
        """ì²­êµ¬í•­ êµ¬ì¡° ê²€ì‚¬"""
        violations = []

        if document_type != "claim":
            return violations

        # ëª…ì‚¬êµ¬ ì¢…ê²° í™•ì¸
        claim_endings = ['ë°©ë²•.', 'ì¥ì¹˜.', 'ì‹œìŠ¤í…œ.', 'í™”í•©ë¬¼.', 'ì¡°ì„±ë¬¼.', 'í‚¤íŠ¸.', 'ìš©ë„.']
        has_proper_ending = any(text.strip().endswith(ending) for ending in claim_endings)

        if not has_proper_ending:
            violations.append(QAViolation(
                rule_id="claim_noun_phrase_ending",
                severity="major",
                description="ì²­êµ¬í•­ì´ ì™„ì „í•œ ëª…ì‚¬êµ¬ë¡œ ì¢…ê²°ë˜ì§€ ì•ŠìŒ",
                location="ë¬¸ì¥ ë",
                found=text.strip()[-30:],
                correct="... ë°©ë²•. / ... ì¥ì¹˜. ë“±"
            ))

        return violations

    def check_punctuation(self, text: str, document_type: str = "claim") -> List[QAViolation]:
        """êµ¬ë‘ì  ê²€ì‚¬ (ì²´í¬ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜)"""
        violations = []

        # 1. ì½œë¡  ì˜¤ìš© ê²€ì‚¬ (ì²­êµ¬í•­ì—ì„œ "~ë¡œì„œ:" ê¸ˆì§€)
        if document_type == "claim":
            colon_after_verb = re.finditer(r'(ë¡œì„œ|ì—ì„œ|ì—|ë¥¼|ì„|ì´|ê°€)\s*:', text)
            for match in colon_after_verb:
                violations.append(QAViolation(
                    rule_id="colon_after_particle",
                    severity="major",
                    description="ì²­êµ¬í•­ì—ì„œ ì¡°ì‚¬ ë’¤ ì½œë¡  ì‚¬ìš© ê¸ˆì§€",
                    location=f"ìœ„ì¹˜: {match.start()}",
                    found=match.group(),
                    correct=match.group(1) + ","
                ))

        # 2. ì„¸ë¯¸ì½œë¡  ì˜¤ìš© ê²€ì‚¬ (ëª©ë¡ ë ì„¸ë¯¸ì½œë¡ )
        semicolon_at_end = re.search(r';\s*$', text.strip())
        if semicolon_at_end:
            violations.append(QAViolation(
                rule_id="semicolon_at_list_end",
                severity="minor",
                description="ëª©ë¡ ë§ˆì§€ë§‰ í•­ëª© ë’¤ ì„¸ë¯¸ì½œë¡  ê¸ˆì§€",
                location="ë¬¸ì¥ ë",
                found="... ;",
                correct="... (ì„¸ë¯¸ì½œë¡  ì œê±°)"
            ))

        return violations

    def check_domain_terms(self, source: str, translation: str) -> List[QAViolation]:
        """ë„ë©”ì¸ë³„ ì˜¤ì—­ ê²€ì‚¬ (ì²´í¬ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜)"""
        violations = []

        for eng_term, rule in self.domain_mistranslations.items():
            # ì›ë¬¸ì— í•´ë‹¹ ì˜ì–´ ìš©ì–´ê°€ ìˆëŠ”ì§€ í™•ì¸
            if eng_term.lower() in source.lower():
                wrong_terms = rule['wrong'] if isinstance(rule['wrong'], list) else [rule['wrong']]

                for wrong_kr in wrong_terms:
                    if wrong_kr in translation:
                        violations.append(QAViolation(
                            rule_id=f"domain_mistranslation_{eng_term.replace(' ', '_')}",
                            severity="major",
                            description=f"'{eng_term}' ì˜¤ì—­: {rule.get('context', '')} ë¬¸ë§¥",
                            location=f"'{wrong_kr}' ë°œê²¬",
                            found=wrong_kr,
                            correct=rule['correct']
                        ))

        return violations

    def check_standard_terminology(self, translation: str) -> List[QAViolation]:
        """í‘œì¤€ ìš©ì–´ ê²€ì‚¬ (ì²´í¬ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜)"""
        violations = []

        # embodiment ë²ˆì—­ ê²€ì‚¬
        forbidden_embodiments = ['ì‹¤ì‹œíƒœì–‘', 'ì‹¤ì‹œì˜ˆ', 'êµ¬í˜„ì˜ˆ']
        for forbidden in forbidden_embodiments:
            if forbidden in translation:
                violations.append(QAViolation(
                    rule_id="embodiment_forbidden_term",
                    severity="minor",
                    description=f"'embodiment' ë²ˆì—­ ì‹œ '{forbidden}' ì‚¬ìš© ì§€ì–‘",
                    location=f"'{forbidden}' ë°œê²¬",
                    found=forbidden,
                    correct="ì‹¤ì‹œí˜•íƒœ (ê¶Œì¥)"
                ))

        # subject matter ì˜¤ì—­ ê²€ì‚¬
        if 'ì£¼ì œ' in translation:
            # "subject matter"ê°€ ì›ë¬¸ì— ìˆì„ ê°€ëŠ¥ì„± ì²´í¬ (ê°„ì ‘ì )
            violations.append(QAViolation(
                rule_id="subject_matter_mistranslation",
                severity="minor",
                description="'subject matter'ë¥¼ 'ì£¼ì œ'ë¡œ ë²ˆì—­ ì§€ì–‘",
                location="'ì£¼ì œ' ë°œê²¬",
                found="ì£¼ì œ",
                correct="ëŒ€ìƒë¬¼ ë˜ëŠ” ëŒ€ìƒ"
            ))

        return violations

    def check_numerical_expressions(self, source: str, translation: str) -> List[QAViolation]:
        """ìˆ˜ì¹˜ í‘œí˜„ ê²€ì‚¬ (ì²´í¬ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜)"""
        violations = []

        # "more than one" ê²€ì‚¬
        if 'more than one' in source.lower():
            if 'í•˜ë‚˜(1ê°œ) ì´ìƒ' in translation or 'í•˜ë‚˜ ì´ìƒ' in translation:
                violations.append(QAViolation(
                    rule_id="more_than_one_mistranslation",
                    severity="major",
                    description="'more than one' ì˜¤ì—­",
                    location="'í•˜ë‚˜ ì´ìƒ' ë°œê²¬",
                    found="í•˜ë‚˜(1ê°œ) ì´ìƒ",
                    correct="ë‘˜(2ê°œ) ì´ìƒ ë˜ëŠ” í•˜ë‚˜(1ê°œ) ì´ˆê³¼"
                ))

        # "less than two" ê²€ì‚¬
        if 'less than two' in source.lower():
            if 'ë‘˜(2ê°œ) ì´í•˜' in translation or 'ë‘˜ ì´í•˜' in translation:
                violations.append(QAViolation(
                    rule_id="less_than_two_mistranslation",
                    severity="major",
                    description="'less than two' ì˜¤ì—­",
                    location="'ë‘˜ ì´í•˜' ë°œê²¬",
                    found="ë‘˜(2ê°œ) ì´í•˜",
                    correct="í•˜ë‚˜(1ê°œ) ì´í•˜ ë˜ëŠ” ë‘˜(2ê°œ) ë¯¸ë§Œ"
                ))

        return violations

    def check_transitional_phrases(self, source: str, translation: str) -> List[QAViolation]:
        """ì „í™˜êµ¬ ê²€ì‚¬ (ì²´í¬ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜)"""
        violations = []

        # "adapted to" íŠ¹ë³„ ê²€ì‚¬
        if 'adapted to' in source.lower():
            if 'ì í•©í™”ëœ' in translation or 'ì ì‘ëœ' in translation:
                violations.append(QAViolation(
                    rule_id="adapted_to_mistranslation",
                    severity="critical",
                    description="'adapted to' ì˜¤ì—­ - ê¶Œë¦¬ë²”ìœ„ ì˜í–¥",
                    location="'ì í•©í™”ëœ' ë˜ëŠ” 'ì ì‘ëœ' ë°œê²¬",
                    found="ì í•©í™”ëœ/ì ì‘ëœ",
                    correct="~í•˜ë„ë¡ êµ¬ì„±ëœ"
                ))

        return violations

    def check_claim_noun_phrase_structure(self, text: str, document_type: str = "claim") -> List[QAViolation]:
        """ì²­êµ¬í•­ ëª…ì‚¬êµ¬ êµ¬ì¡° ìƒì„¸ ê²€ì‚¬"""
        violations = []

        if document_type != "claim":
            return violations

        # ë°©ë²• ì²­êµ¬í•­ êµ¬ì¡° ê²€ì‚¬
        if 'ë°©ë²•' in text:
            # "ë°©ë²•ìœ¼ë¡œì„œ," ë˜ëŠ” "ë°©ë²•ì— ìˆì–´ì„œ,"ë¡œ ì‹œì‘í•˜ëŠ”ì§€
            if not (re.search(r'ë°©ë²•ìœ¼ë¡œì„œ,', text) or re.search(r'ë°©ë²•ì—\s*ìˆì–´ì„œ,', text)):
                violations.append(QAViolation(
                    rule_id="method_claim_preamble",
                    severity="major",
                    description="ë°©ë²• ì²­êµ¬í•­ì€ '~ë°©ë²•ìœ¼ë¡œì„œ,' ë˜ëŠ” '~ë°©ë²•ì— ìˆì–´ì„œ,'ë¡œ ì‹œì‘ ê¶Œì¥",
                    location="ì²­êµ¬í•­ ì‹œì‘ ë¶€ë¶„",
                    found=text[:50] + "...",
                    correct="~ë°©ë²•ìœ¼ë¡œì„œ, ... ë˜ëŠ” ~ë°©ë²•ì— ìˆì–´ì„œ, ..."
                ))

            # "~ë¥¼ í¬í•¨í•˜ëŠ” ë°©ë²•." ë˜ëŠ” "~ë°©ë²•." í˜•ì‹ìœ¼ë¡œ ëë‚˜ëŠ”ì§€
            proper_endings = [
                r'í¬í•¨í•˜ëŠ”\s*ë°©ë²•\.$',
                r'íŠ¹ì„±í™”ë˜ëŠ”,?\s*ë°©ë²•\.$',
                r'ì´ë£¨ì–´ì§€ëŠ”\s*ë°©ë²•\.$',
                r'êµ¬ì„±ë˜ëŠ”\s*ë°©ë²•\.$'
            ]
            has_proper_ending = any(re.search(pattern, text) for pattern in proper_endings)

            if not has_proper_ending and text.strip().endswith('ë°©ë²•.'):
                # ë°©ë²•ìœ¼ë¡œ ëë‚˜ê¸´ í•˜ëŠ”ë° ì ì ˆí•œ í˜•ì‹ì´ ì•„ë‹ ìˆ˜ ìˆìŒ
                violations.append(QAViolation(
                    rule_id="method_claim_ending_structure",
                    severity="minor",
                    description="ë°©ë²• ì²­êµ¬í•­ ì¢…ê²° êµ¬ì¡° í™•ì¸ í•„ìš”",
                    location="ì²­êµ¬í•­ ë",
                    found=text[-50:],
                    correct="~ë¥¼ í¬í•¨í•˜ëŠ” ë°©ë²•. ë˜ëŠ” ~íŠ¹ì„±í™”ë˜ëŠ”, ë°©ë²•."
                ))

        return violations

    def check_all(self, source: str, translation: str,
                  term_mapping: Dict[str, str],
                  document_type: str = "claim") -> Dict:
        """ì „ì²´ QA ê²€ì‚¬ (QA_CHECKLIST.md ê¸°ë°˜ í¬ê´„ì  ê²€ì‚¬)"""

        print("ğŸ” QA ê²€ì¦ ì¤‘ (QA_CHECKLIST.md ê¸°ë°˜)...")

        self.violations = []

        # 1. í˜•ì‹ ê²€ì‚¬
        self.violations.extend(self.check_formatting(translation, document_type))
        print(f"   âœ“ í˜•ì‹ ê²€ì‚¬ ì™„ë£Œ")

        # 2. ìš©ì–´ ê²€ì‚¬ (ê¸°ì¡´)
        self.violations.extend(self.check_terminology(translation, term_mapping))
        print(f"   âœ“ ìš©ì–´ ê²€ì‚¬ ì™„ë£Œ")

        # 3. ì„ í–‰ì‚¬ ê²€ì‚¬
        self.violations.extend(self.check_antecedent_basis(source, translation))
        print(f"   âœ“ ì„ í–‰ì‚¬ ê²€ì‚¬ ì™„ë£Œ")

        # 4. ì²­êµ¬í•­ êµ¬ì¡° ê²€ì‚¬
        if document_type == "claim":
            self.violations.extend(self.check_claim_structure(translation, document_type))
            print(f"   âœ“ ì²­êµ¬í•­ êµ¬ì¡° ê²€ì‚¬ ì™„ë£Œ")

        # === QA_CHECKLIST.md ê¸°ë°˜ ì¶”ê°€ ê²€ì‚¬ ===

        # 5. êµ¬ë‘ì  ê²€ì‚¬
        self.violations.extend(self.check_punctuation(translation, document_type))
        print(f"   âœ“ êµ¬ë‘ì  ê²€ì‚¬ ì™„ë£Œ")

        # 6. ë„ë©”ì¸ë³„ ì˜¤ì—­ ê²€ì‚¬
        self.violations.extend(self.check_domain_terms(source, translation))
        print(f"   âœ“ ë„ë©”ì¸ë³„ ìš©ì–´ ê²€ì‚¬ ì™„ë£Œ")

        # 7. í‘œì¤€ ìš©ì–´ ê²€ì‚¬
        self.violations.extend(self.check_standard_terminology(translation))
        print(f"   âœ“ í‘œì¤€ ìš©ì–´ ê²€ì‚¬ ì™„ë£Œ")

        # 8. ìˆ˜ì¹˜ í‘œí˜„ ê²€ì‚¬
        self.violations.extend(self.check_numerical_expressions(source, translation))
        print(f"   âœ“ ìˆ˜ì¹˜ í‘œí˜„ ê²€ì‚¬ ì™„ë£Œ")

        # 9. ì „í™˜êµ¬ ê²€ì‚¬
        self.violations.extend(self.check_transitional_phrases(source, translation))
        print(f"   âœ“ ì „í™˜êµ¬ ê²€ì‚¬ ì™„ë£Œ")

        # 10. ì²­êµ¬í•­ ëª…ì‚¬êµ¬ êµ¬ì¡° ìƒì„¸ ê²€ì‚¬
        if document_type == "claim":
            self.violations.extend(self.check_claim_noun_phrase_structure(translation, document_type))
            print(f"   âœ“ ì²­êµ¬í•­ ëª…ì‚¬êµ¬ êµ¬ì¡° ìƒì„¸ ê²€ì‚¬ ì™„ë£Œ")

        # ê²°ê³¼ ì§‘ê³„
        severity_counts = {
            "critical": 0,
            "major": 0,
            "minor": 0,
            "neutral": 0
        }

        for v in self.violations:
            severity_counts[v.severity] = severity_counts.get(v.severity, 0) + 1

        print(f"\nğŸ“Š QA ê²°ê³¼:")
        print(f"   Critical: {severity_counts['critical']}")
        print(f"   Major: {severity_counts['major']}")
        print(f"   Minor: {severity_counts['minor']}")
        print(f"   Neutral: {severity_counts['neutral']}")

        return {
            "total_violations": len(self.violations),
            "severity_counts": severity_counts,
            "violations": [v.to_dict() for v in self.violations],
            "passed": severity_counts['critical'] == 0 and severity_counts['major'] == 0
        }

    def generate_report(self, qa_result: Dict) -> str:
        """QA ë¦¬í¬íŠ¸ ìƒì„± (QA_CHECKLIST.md ê¸°ë°˜)"""
        report = ["=" * 60]
        report.append("ğŸ“‹ íŠ¹í—ˆ ë²ˆì—­ QA ë¦¬í¬íŠ¸ (QA_CHECKLIST.md ê¸°ë°˜)")
        report.append("=" * 60)
        report.append("")

        # ìš”ì•½
        report.append("## ìš”ì•½")
        report.append(f"ì´ ìœ„ë°˜ ì‚¬í•­: {qa_result['total_violations']}ê°œ")
        report.append(f"í†µê³¼ ì—¬ë¶€: {'âœ… PASS' if qa_result['passed'] else 'âŒ FAIL'}")
        report.append("")

        # ì‹¬ê°ë„ë³„ ì§‘ê³„
        report.append("## ì‹¬ê°ë„ë³„ ì§‘ê³„")
        report.append(f"  CRITICAL (ì¹˜ëª…ì ): {qa_result['severity_counts']['critical']}ê°œ - ìë™ ì‹¤íŒ¨")
        report.append(f"  MAJOR (ì¤‘ëŒ€): {qa_result['severity_counts']['major']}ê°œ - í’ˆì§ˆ ì €í•˜")
        report.append(f"  MINOR (ê²½ë¯¸): {qa_result['severity_counts']['minor']}ê°œ - ê°œì„  ê¶Œì¥")
        report.append(f"  NEUTRAL (ì¤‘ë¦½): {qa_result['severity_counts']['neutral']}ê°œ - ì°¸ê³ ìš©")
        report.append("")

        # QA ê²€ì‚¬ í•­ëª©
        report.append("## ì‹¤í–‰ëœ QA ê²€ì‚¬ í•­ëª© (10ê°œ)")
        report.append("  1. âœ“ í˜•ì‹ ê²€ì‚¬ (ì˜¨ë„, í¼ì„¼íŠ¸, ì„œì—´ë²ˆí˜¸, ì²­êµ¬í•­ ë§ˆì¹¨í‘œ)")
        report.append("  2. âœ“ ìš©ì–´ ì¼ê´€ì„± ê²€ì‚¬ (ê¸ˆì§€ ìš©ì–´)")
        report.append("  3. âœ“ ì„ í–‰ì‚¬ 'ìƒê¸°' ê²€ì‚¬")
        report.append("  4. âœ“ ì²­êµ¬í•­ êµ¬ì¡° ê²€ì‚¬ (ëª…ì‚¬êµ¬ ì¢…ê²°)")
        report.append("  5. âœ“ êµ¬ë‘ì  ê²€ì‚¬ (ì½œë¡ , ì„¸ë¯¸ì½œë¡  ì˜¤ìš©)")
        report.append("  6. âœ“ ë„ë©”ì¸ë³„ ì˜¤ì—­ ê²€ì‚¬ (substrate, detach, distal/proximal end ë“±)")
        report.append("  7. âœ“ í‘œì¤€ ìš©ì–´ ê²€ì‚¬ (embodiment, aspect, subject matter)")
        report.append("  8. âœ“ ìˆ˜ì¹˜ í‘œí˜„ ê²€ì‚¬ (more than one, less than two)")
        report.append("  9. âœ“ ì „í™˜êµ¬ ê²€ì‚¬ (adapted to ë“±)")
        report.append(" 10. âœ“ ì²­êµ¬í•­ ëª…ì‚¬êµ¬ êµ¬ì¡° ìƒì„¸ ê²€ì‚¬")
        report.append("")
        report.append("ğŸ“– ì „ì²´ ê°€ì´ë“œë¼ì¸: config/QA_CHECKLIST.md ì°¸ì¡°")
        report.append("")

        # ìƒì„¸ ìœ„ë°˜ ì‚¬í•­
        if qa_result['violations']:
            report.append("## ìƒì„¸ ìœ„ë°˜ ì‚¬í•­")
            report.append("")

            for i, v in enumerate(qa_result['violations'], 1):
                report.append(f"### [{i}] {v['rule_id']} ({v['severity'].upper()})")
                report.append(f"ì„¤ëª…: {v['description']}")
                report.append(f"ìœ„ì¹˜: {v['location']}")
                report.append(f"ë°œê²¬: {v['found']}")
                if v['correct']:
                    report.append(f"ìˆ˜ì •: {v['correct']}")
                report.append("")

        report.append("=" * 60)

        return "\n".join(report)


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    checker = PatentQAChecker()

    source = "A method comprising the compound"
    translation = "í™”í•©ë¬¼ì„ í¬í•¨í•˜ëŠ” ë°©ë²•"  # "ìƒê¸°" ëˆ„ë½
    term_mapping = {"compound": "í™”í•©ë¬¼", "method": "ë°©ë²•"}

    result = checker.check_all(source, translation, term_mapping, document_type="claim")
    report = checker.generate_report(result)

    print(report)
